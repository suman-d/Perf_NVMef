{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def ParseArgs():\n",
    "    \"\"\"Parse command line options into globals.\"\"\"\n",
    "    global result_folder\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "                 formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    description=\"This is a part of KumoScale Performance QA Regression Testing tool. \\n\" \\\n",
    "                \"The module will will move all the required file which would be used \\n\" \\\n",
    "                \"for the data analysis and reporting, this should be used once a test \\n\" \\\n",
    "                \"run is complete\",\n",
    "    epilog=\"\"\"\n",
    "    Requirements:\\n\n",
    "    * Already completed a test run using \"nvmef_perf\" tool and the \"Result\" folder is available\n",
    "    \\n\\n\n",
    "    \"\"\")\n",
    "    parser.add_argument(\"--resultFolder\", \"-f\", dest = \"result_folder\",\n",
    "        help=\"Provide the full path of the Test Result Folder\", required=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    result_folder = args.result_folder\n",
    "\n",
    "def csv_to_df(csv_file):\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df.Timestamp, format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df[\"Stat_Start_Time\"] = df[\"Timestamp\"] - datetime.timedelta(seconds=110)\n",
    "    df[\"Stat_End_Time\"] = df[\"Timestamp\"] - datetime.timedelta(seconds=10)\n",
    "    df.index = pd.RangeIndex(1, len(df.index)+1)\n",
    "\n",
    "    df.columns = [i.strip() for i in df.columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "def merg_df(df1, df2):\n",
    "\n",
    "    frames = [df1, df2]\n",
    "    merg = pd.concat(frames, axis=0)\n",
    "    merg.index = pd.RangeIndex(1, len(merg.index)+1)\n",
    "\n",
    "    return merg\n",
    "\n",
    "def combine_df(df1, df2):\n",
    "\n",
    "    combine = df1.copy()\n",
    "    #row_index = df1.index\n",
    "\n",
    "    prams_avg = [\"Read Latency (us)\", \"Write Latency (us)\"]\n",
    "    prams_sum = [\"IOPS\", \"Bandwidth (MB/s)\"]\n",
    "    for p in prams_sum:\n",
    "        combine[p] = combine[p] + df2[p]\n",
    "    for p in prams_avg:\n",
    "        combine[p] = (combine[p] + df2[p]) / 2\n",
    "\n",
    "    combine[\"Host2_CPU_Utilization\"] = df2[\"Host2_CPU_Utilization\"]\n",
    "    combine[\"Host2_Memory_Utilization\"] = df2[\"Host2_Memory_Utilization\"]\n",
    "\n",
    "    return combine\n",
    "\n",
    "def df_to_csv(df, file_name):\n",
    "\n",
    "    df.to_csv(file_name,index=False)\n",
    "    file_path = os.path.abspath(file_name)\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def json_to_df(json_file):\n",
    "\n",
    "    df_stat = pd.read_json(json_file, orient='index')\n",
    "    df_stat.columns = [\"CPU_Utilization\", \"Memory_Utilization\"]\n",
    "    df_stat[\"Timestamp\"] = pd.to_datetime(df_stat.index, format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "    #df_stat.index = df_stat[\"Timestamp\"]\n",
    "    df_stat.index = pd.RangeIndex(1, len(df_stat.index)+1)\n",
    "\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def file_scanner(list_files):\n",
    "\n",
    "    global host1_tput_file, host1_lat_file, host2_tput_file, stat_appliance_lat_file\n",
    "    global stat_appliance_tput_file, stat_host1_lat_file, stat_host1_tput_file, stat_host2_tput_file\n",
    "\n",
    "    host1_files = []\n",
    "\n",
    "    for file in list_files:\n",
    "        _file = os.path.basename(file)\n",
    "        if _file.startswith(\"ezfio_tests_\"):\n",
    "            if \"host1\" in _file.split(\"_\"):\n",
    "                host1_files.append(file)\n",
    "            else:\n",
    "                host2_tput_file = file\n",
    "        elif _file.startswith(\"lat_appliance\"):\n",
    "            stat_appliance_lat_file = file\n",
    "        elif _file.startswith(\"tput_appliance\"):\n",
    "            stat_appliance_tput_file = file\n",
    "        elif _file.startswith(\"lat_host1\"):\n",
    "            stat_host1_lat_file = file\n",
    "        elif _file.startswith(\"tput_host1\"):\n",
    "            stat_host1_tput_file = file\n",
    "        elif _file.startswith(\"tput_host2\"):\n",
    "            stat_host2_tput_file = file\n",
    "\n",
    "    _host1_files = {}\n",
    "    for file in host1_files:\n",
    "        _file = os.path.basename(file)\n",
    "        _t = _file.split(\"_\")[2].split(\"GB\")[0]\n",
    "        _host1_files[int(_t)] = file\n",
    "\n",
    "    lat, tput = sorted(_host1_files)\n",
    "    host1_tput_file = _host1_files[tput]\n",
    "    host1_lat_file = _host1_files[lat]\n",
    "\n",
    "def cpu_mem_avg_calculator(stat_df, start_time, end_time):\n",
    "\n",
    "    c_util, m_util = stat_df[(stat_df[\"Timestamp\"] >= start_time) & (stat_df[\"Timestamp\"] <= end_time)].mean()\n",
    "    return int(c_util), int(m_util)\n",
    "\n",
    "def add_cpu_mem_stat(master_df, stat_df, host_name):\n",
    "\n",
    "    cpu_util = []\n",
    "    mem_util = []\n",
    "    for _, row in master_df.iterrows():\n",
    "        start, end = row[\"Stat_Start_Time\"], row[\"Stat_End_Time\"]\n",
    "        c, m = cpu_mem_avg_calculator(stat_df, start, end)\n",
    "        cpu_util.append(c)\n",
    "        mem_util.append(m)\n",
    "\n",
    "    cpu_col_name = host_name + \"_CPU_Utilization\"\n",
    "    mem_col_name = host_name + \"_Memory_Utilization\"\n",
    "    master_df[cpu_col_name] = cpu_util\n",
    "    master_df[mem_col_name] = mem_util\n",
    "\n",
    "    return  master_df\n",
    "\n",
    "result_folder = \"\"\n",
    "\n",
    "host1_tput_file = \"\"\n",
    "host1_lat_file = \"\"\n",
    "host2_tput_file = \"\"\n",
    "stat_appliance_lat_file = \"\"\n",
    "stat_appliance_tput_file = \"\"\n",
    "stat_host1_lat_file = \"\"\n",
    "stat_host1_tput_file = \"\"\n",
    "stat_host2_tput_file = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "result_folder = os.path.join(pwd, \"Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_folder_path = os.path.join(result_folder, \"post_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #time.sleep(2)\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "    # Filtering the required files from Host1, Host2 and Appliance\n",
    "    files_to_copy = []\n",
    "    for root, dirs, files in os.walk(result_folder, topdown=False):\n",
    "        for name in files:\n",
    "            if name.startswith(\"ezfio_tests_\") or name.startswith(\"host\") or name.startswith(\"lat_\") or name.startswith(\"tput_\"):\n",
    "                files_to_copy.append((os.path.join(root, name)))\n",
    "\n",
    "    # Copying all the files to \"post_run\" folder\n",
    "    for f in files_to_copy:\n",
    "        shutil.copy(f, new_folder_path)\n",
    "\n",
    "    # Printing the path of the new_folder and its file contents\n",
    "    print(\"*\"*120)\n",
    "    print(\"This is the folder path which contains all the files :  {}\".format(new_folder_path))\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    print(\"Here are the files: \")\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    list_files = []\n",
    "    for f in (os.listdir(new_folder_path)):\n",
    "        file_path = os.path.join(new_folder_path, f)\n",
    "        print(file_path)\n",
    "        list_files.append(file_path)\n",
    "\n",
    "    print(\"*\"*120)\n",
    "    print(\"Computing the Data Collection for IOPS, Throughput, Latency, CPU/Mem Utilization for Host1, Host2 and Appliance\")\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    # Identifying the test files for Host1, Host2 and Appliance\n",
    "\n",
    "    file_scanner(list_files)\n",
    "\n",
    "    # Loading the all the CSV files to DataFrame\n",
    "\n",
    "    # Loading IO,TPUT and Latency Test Data for Host1\n",
    "    df_host1_tput = csv_to_df(host1_tput_file)\n",
    "    df_host1_lat = csv_to_df(host1_lat_file)\n",
    "\n",
    "    # Loading IO,TPUT Test Data for Host2\n",
    "    df_host2_tput = csv_to_df(host2_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Host1\n",
    "    df_stat_host1_lat = json_to_df(stat_host1_lat_file)\n",
    "    df_stat_host1_tput = json_to_df(stat_host1_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Host2\n",
    "    df_stat_host2_tput = json_to_df(stat_host2_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Appliance\n",
    "    df_stat_appliance_lat = json_to_df(stat_appliance_lat_file)\n",
    "    df_stat_appliance_tput = json_to_df(stat_appliance_tput_file)\n",
    "\n",
    "    # Calculating the CPU and Memory Utilization and adding to the DataFrame\n",
    "\n",
    "    df_host1_lat = add_cpu_mem_stat(df_host1_lat, df_stat_host1_lat, \"Host1\")\n",
    "    df_host1_tput = add_cpu_mem_stat(df_host1_tput, df_stat_host1_tput, \"Host1\")\n",
    "    df_host1_lat = add_cpu_mem_stat(df_host1_lat, df_stat_appliance_lat, \"Appliance\")\n",
    "    df_host1_tput = add_cpu_mem_stat(df_host1_tput, df_stat_appliance_tput, \"Appliance\")\n",
    "    df_host2_tput = add_cpu_mem_stat(df_host2_tput, df_stat_host2_tput, \"Host2\")\n",
    "\n",
    "    # Combining Host1 and Host2 Results after CPU and Memory Calculation\n",
    "\n",
    "    df = combine_df(df1=df_host1_tput, df2=df_host2_tput)\n",
    "\n",
    "    # Adding the Latency Results to the final DataFrame\n",
    "\n",
    "    df_final = merg_df(df, df_host1_lat)\n",
    "\n",
    "    # Saving the final DataFrame to a CSV File\n",
    "\n",
    "    final_csv_file_path = result_folder + \"/final.csv\"\n",
    "    df_to_csv(df_final, final_csv_file_path)\n",
    "\n",
    "    # Copying the same file inside the \"post_run\" folder as well\n",
    "\n",
    "    shutil.copy(final_csv_file_path, new_folder_path)\n",
    "\n",
    "    # Printing the path of the final.csv\n",
    "    print(\"Here is the path of the final CSV :\")\n",
    "    print(final_csv_file_path)\n",
    "    print(\"*\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
