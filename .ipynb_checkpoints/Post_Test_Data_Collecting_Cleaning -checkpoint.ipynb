{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def ParseArgs():\n",
    "    \"\"\"Parse command line options into globals.\"\"\"\n",
    "    global result_folder\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "                 formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    description=\"This is a part of KumoScale Performance QA Regression Testing tool. \\n\" \\\n",
    "                \"The module will will move all the required file which would be used \\n\" \\\n",
    "                \"for the data analysis and reporting, this should be used once a test \\n\" \\\n",
    "                \"run is complete\",\n",
    "    epilog=\"\"\"\n",
    "    Requirements:\\n\n",
    "    * Already completed a test run using \"nvmef_perf\" tool and the \"Result\" folder is available\n",
    "    \\n\\n\n",
    "    \"\"\")\n",
    "    parser.add_argument(\"--resultFolder\", \"-f\", dest = \"result_folder\",\n",
    "        help=\"Provide the full path of the Test Result Folder\", required=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    result_folder = args.result_folder\n",
    "\n",
    "def csv_to_df(csv_file):\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df.Timestamp, format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df[\"Stat_Start_Time\"] = df[\"Timestamp\"] - datetime.timedelta(seconds=110)\n",
    "    df[\"Stat_End_Time\"] = df[\"Timestamp\"] - datetime.timedelta(seconds=10)\n",
    "    df.index = pd.RangeIndex(1, len(df.index)+1)\n",
    "\n",
    "    df.columns = [i.strip() for i in df.columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "def merg_df(df1, df2):\n",
    "\n",
    "    frames = [df1, df2]\n",
    "    merg = pd.concat(frames, axis=0)\n",
    "    merg.index = pd.RangeIndex(1, len(merg.index)+1)\n",
    "\n",
    "    return merg\n",
    "\n",
    "def combine_df(df1, df2):\n",
    "\n",
    "    combine = df1.copy()\n",
    "    #row_index = df1.index\n",
    "\n",
    "    prams_avg = [\"Read Latency (us)\", \"Write Latency (us)\"]\n",
    "    prams_sum = [\"IOPS\", \"Bandwidth (MB/s)\"]\n",
    "    for p in prams_sum:\n",
    "        combine[p] = combine[p] + df2[p]\n",
    "    for p in prams_avg:\n",
    "        combine[p] = (combine[p] + df2[p]) / 2\n",
    "\n",
    "    combine[\"Host2_CPU_Utilization\"] = df2[\"Host2_CPU_Utilization\"]\n",
    "    combine[\"Host2_Memory_Utilization\"] = df2[\"Host2_Memory_Utilization\"]\n",
    "\n",
    "    return combine\n",
    "\n",
    "def df_to_csv(df, file_name):\n",
    "\n",
    "    df.to_csv(file_name,index=False)\n",
    "    file_path = os.path.abspath(file_name)\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def json_to_df(json_file):\n",
    "\n",
    "    df_stat = pd.read_json(json_file, orient='index')\n",
    "    df_stat.columns = [\"CPU_Utilization\", \"Memory_Utilization\"]\n",
    "    df_stat[\"Timestamp\"] = pd.to_datetime(df_stat.index, format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "    #df_stat.index = df_stat[\"Timestamp\"]\n",
    "    df_stat.index = pd.RangeIndex(1, len(df_stat.index)+1)\n",
    "\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def file_scanner(list_files):\n",
    "\n",
    "    global host1_tput_file, host1_lat_file, host2_tput_file, stat_appliance_lat_file\n",
    "    global stat_appliance_tput_file, stat_host1_lat_file, stat_host1_tput_file, stat_host2_tput_file\n",
    "\n",
    "    host1_files = []\n",
    "\n",
    "    for file in list_files:\n",
    "        _file = os.path.basename(file)\n",
    "        if _file.startswith(\"ezfio_tests_\"):\n",
    "            if \"host1\" in _file.split(\"_\"):\n",
    "                host1_files.append(file)\n",
    "            else:\n",
    "                host2_tput_file = file\n",
    "        elif _file.startswith(\"lat_appliance\"):\n",
    "            stat_appliance_lat_file = file\n",
    "        elif _file.startswith(\"tput_appliance\"):\n",
    "            stat_appliance_tput_file = file\n",
    "        elif _file.startswith(\"lat_host1\"):\n",
    "            stat_host1_lat_file = file\n",
    "        elif _file.startswith(\"tput_host1\"):\n",
    "            stat_host1_tput_file = file\n",
    "        elif _file.startswith(\"tput_host2\"):\n",
    "            stat_host2_tput_file = file\n",
    "\n",
    "    _host1_files = {}\n",
    "    for file in host1_files:\n",
    "        _file = os.path.basename(file)\n",
    "        _t = _file.split(\"_\")[2].split(\"GB\")[0]\n",
    "        _host1_files[int(_t)] = file\n",
    "\n",
    "    lat, tput = sorted(_host1_files)\n",
    "    host1_tput_file = _host1_files[tput]\n",
    "    host1_lat_file = _host1_files[lat]\n",
    "\n",
    "def cpu_mem_avg_calculator(stat_df, start_time, end_time):\n",
    "\n",
    "    c_util, m_util = stat_df[(stat_df[\"Timestamp\"] >= start_time) & (stat_df[\"Timestamp\"] <= end_time)].mean()\n",
    "    return int(c_util), int(m_util)\n",
    "\n",
    "def add_cpu_mem_stat(master_df, stat_df, host_name):\n",
    "\n",
    "    cpu_util = []\n",
    "    mem_util = []\n",
    "    for _, row in master_df.iterrows():\n",
    "        start, end = row[\"Stat_Start_Time\"], row[\"Stat_End_Time\"]\n",
    "        c, m = cpu_mem_avg_calculator(stat_df, start, end)\n",
    "        cpu_util.append(c)\n",
    "        mem_util.append(m)\n",
    "\n",
    "    cpu_col_name = host_name + \"_CPU_Utilization\"\n",
    "    mem_col_name = host_name + \"_Memory_Utilization\"\n",
    "    master_df[cpu_col_name] = cpu_util\n",
    "    master_df[mem_col_name] = mem_util\n",
    "\n",
    "    return  master_df\n",
    "\n",
    "result_folder = \"\"\n",
    "\n",
    "host1_tput_file = \"\"\n",
    "host1_lat_file = \"\"\n",
    "host2_tput_file = \"\"\n",
    "stat_appliance_lat_file = \"\"\n",
    "stat_appliance_tput_file = \"\"\n",
    "stat_host1_lat_file = \"\"\n",
    "stat_host1_tput_file = \"\"\n",
    "stat_host2_tput_file = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "result_folder = os.path.join(pwd, \"Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\p_results2\\\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_folder_path = os.path.join(result_folder, \"post_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\p_results2\\\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\\\post_run'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "This is the folder path which contains all the files :  D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\n",
      "************************************************************************************************************************\n",
      "Here are the files: \n",
      "************************************************************************************************************************\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\ezfio_tests_4788GB_48cores_2200MHz_nvme0n1_host1_2018-05-07_12-31-03.csv\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\ezfio_tests_4788GB_48cores_2200MHz_nvme0n1_host2_2018-05-07_12-31-03.csv\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\ezfio_tests_798GB_48cores_2200MHz_nvme0n1_host1_2018-05-07_14-31-04.csv\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\lat_appliance_2018-05-07_16-39-25_cpu_mem_stat.json\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\lat_host1_2018-05-07_16-31-13_cpu_mem_stat.json\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\tput_appliance_2018-05-07_14-30-29_cpu_mem_stat.json\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\tput_host1_2018-05-07_14-23-12_cpu_mem_stat.json\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47\\post_run\\tput_host2_2018-05-07_14-23-12_cpu_mem_stat.json\n",
      "************************************************************************************************************************\n",
      "Computing the Data Collection for IOPS, Throughput, Latency, CPU/Mem Utilization for Host1, Host2 and Appliance\n",
      "************************************************************************************************************************\n",
      "Here is the path of the final CSV :\n",
      "D:\\p_results2\\Results_baseline_abstract_3.6.10307_2018-05-07_12-30-47/final.csv\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "    #time.sleep(2)\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "    # Filtering the required files from Host1, Host2 and Appliance\n",
    "    files_to_copy = []\n",
    "    for root, dirs, files in os.walk(result_folder, topdown=False):\n",
    "        for name in files:\n",
    "            if name.startswith(\"ezfio_tests_\") or name.startswith(\"host\") or name.startswith(\"lat_\") or name.startswith(\"tput_\"):\n",
    "                files_to_copy.append((os.path.join(root, name)))\n",
    "\n",
    "    # Copying all the files to \"post_run\" folder\n",
    "    for f in files_to_copy:\n",
    "        shutil.copy(f, new_folder_path)\n",
    "\n",
    "    # Printing the path of the new_folder and its file contents\n",
    "    print(\"*\"*120)\n",
    "    print(\"This is the folder path which contains all the files :  {}\".format(new_folder_path))\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    print(\"Here are the files: \")\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    list_files = []\n",
    "    for f in (os.listdir(new_folder_path)):\n",
    "        file_path = os.path.join(new_folder_path, f)\n",
    "        print(file_path)\n",
    "        list_files.append(file_path)\n",
    "\n",
    "    print(\"*\"*120)\n",
    "    print(\"Computing the Data Collection for IOPS, Throughput, Latency, CPU/Mem Utilization for Host1, Host2 and Appliance\")\n",
    "    print(\"*\"*120)\n",
    "\n",
    "    # Identifying the test files for Host1, Host2 and Appliance\n",
    "\n",
    "    file_scanner(list_files)\n",
    "\n",
    "    # Loading the all the CSV files to DataFrame\n",
    "\n",
    "    # Loading IO,TPUT and Latency Test Data for Host1\n",
    "    df_host1_tput = csv_to_df(host1_tput_file)\n",
    "    df_host1_lat = csv_to_df(host1_lat_file)\n",
    "\n",
    "    # Loading IO,TPUT Test Data for Host2\n",
    "    df_host2_tput = csv_to_df(host2_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Host1\n",
    "    df_stat_host1_lat = json_to_df(stat_host1_lat_file)\n",
    "    df_stat_host1_tput = json_to_df(stat_host1_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Host2\n",
    "    df_stat_host2_tput = json_to_df(stat_host2_tput_file)\n",
    "\n",
    "    # Loading the CPU and Mem stats for Appliance\n",
    "    df_stat_appliance_lat = json_to_df(stat_appliance_lat_file)\n",
    "    df_stat_appliance_tput = json_to_df(stat_appliance_tput_file)\n",
    "\n",
    "    # Calculating the CPU and Memory Utilization and adding to the DataFrame\n",
    "\n",
    "    df_host1_lat = add_cpu_mem_stat(df_host1_lat, df_stat_host1_lat, \"Host1\")\n",
    "    df_host1_tput = add_cpu_mem_stat(df_host1_tput, df_stat_host1_tput, \"Host1\")\n",
    "    df_host1_lat = add_cpu_mem_stat(df_host1_lat, df_stat_appliance_lat, \"Appliance\")\n",
    "    df_host1_tput = add_cpu_mem_stat(df_host1_tput, df_stat_appliance_tput, \"Appliance\")\n",
    "    df_host2_tput = add_cpu_mem_stat(df_host2_tput, df_stat_host2_tput, \"Host2\")\n",
    "\n",
    "    # Combining Host1 and Host2 Results after CPU and Memory Calculation\n",
    "\n",
    "    df = combine_df(df1=df_host1_tput, df2=df_host2_tput)\n",
    "\n",
    "    # Adding the Latency Results to the final DataFrame\n",
    "\n",
    "    df_final = merg_df(df, df_host1_lat)\n",
    "\n",
    "    # Saving the final DataFrame to a CSV File\n",
    "\n",
    "    final_csv_file_path = result_folder + \"/final.csv\"\n",
    "    df_to_csv(df_final, final_csv_file_path)\n",
    "\n",
    "    # Copying the same file inside the \"post_run\" folder as well\n",
    "\n",
    "    shutil.copy(final_csv_file_path, new_folder_path)\n",
    "\n",
    "    # Printing the path of the final.csv\n",
    "    print(\"Here is the path of the final CSV :\")\n",
    "    print(final_csv_file_path)\n",
    "    print(\"*\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliance_CPU_Utilization</th>\n",
       "      <th>Appliance_Memory_Utilization</th>\n",
       "      <th>Bandwidth (MB/s)</th>\n",
       "      <th>Block Size</th>\n",
       "      <th>Host1_CPU_Utilization</th>\n",
       "      <th>Host1_Memory_Utilization</th>\n",
       "      <th>Host2_CPU_Utilization</th>\n",
       "      <th>Host2_Memory_Utilization</th>\n",
       "      <th>IOPS</th>\n",
       "      <th>Queue Depth/Thread</th>\n",
       "      <th>...</th>\n",
       "      <th>Stat_End_Time</th>\n",
       "      <th>Stat_Start_Time</th>\n",
       "      <th>Test_Name</th>\n",
       "      <th>Threads</th>\n",
       "      <th>Time_date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Timestamp_ms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Write %</th>\n",
       "      <th>Write Latency (us)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>261.71</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>535996</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-07 12:33:03</td>\n",
       "      <td>2018-05-07 12:31:23</td>\n",
       "      <td>Sustained Multi-Threaded Sequential Read Tests...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May  7 12:33:13 2018</td>\n",
       "      <td>2018-05-07 12:33:13</td>\n",
       "      <td>1525676593609</td>\n",
       "      <td>Seq</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>530.96</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>543705</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-07 12:35:14</td>\n",
       "      <td>2018-05-07 12:33:34</td>\n",
       "      <td>Sustained Multi-Threaded Sequential Read Tests...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May  7 12:35:24 2018</td>\n",
       "      <td>2018-05-07 12:35:24</td>\n",
       "      <td>1525676724726</td>\n",
       "      <td>Seq</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1056.79</td>\n",
       "      <td>2048</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>541073</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-07 12:37:25</td>\n",
       "      <td>2018-05-07 12:35:45</td>\n",
       "      <td>Sustained Multi-Threaded Sequential Read Tests...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May  7 12:37:35 2018</td>\n",
       "      <td>2018-05-07 12:37:35</td>\n",
       "      <td>1525676855874</td>\n",
       "      <td>Seq</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2237.39</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>572772</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-07 12:39:37</td>\n",
       "      <td>2018-05-07 12:37:57</td>\n",
       "      <td>Sustained Multi-Threaded Sequential Read Tests...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May  7 12:39:47 2018</td>\n",
       "      <td>2018-05-07 12:39:47</td>\n",
       "      <td>1525676987008</td>\n",
       "      <td>Seq</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3894.74</td>\n",
       "      <td>8192</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>498526</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-07 12:41:48</td>\n",
       "      <td>2018-05-07 12:40:08</td>\n",
       "      <td>Sustained Multi-Threaded Sequential Read Tests...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May  7 12:41:58 2018</td>\n",
       "      <td>2018-05-07 12:41:58</td>\n",
       "      <td>1525677118124</td>\n",
       "      <td>Seq</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Appliance_CPU_Utilization  Appliance_Memory_Utilization  Bandwidth (MB/s)  \\\n",
       "1                          6                            10            261.71   \n",
       "2                          6                            10            530.96   \n",
       "3                          6                            10           1056.79   \n",
       "4                          5                            10           2237.39   \n",
       "5                          7                            10           3894.74   \n",
       "\n",
       "   Block Size  Host1_CPU_Utilization  Host1_Memory_Utilization  \\\n",
       "1         512                      2                         2   \n",
       "2        1024                      2                         2   \n",
       "3        2048                      2                         2   \n",
       "4        4096                      2                         2   \n",
       "5        8192                      2                         2   \n",
       "\n",
       "   Host2_CPU_Utilization  Host2_Memory_Utilization    IOPS  \\\n",
       "1                    2.0                       2.0  535996   \n",
       "2                    2.0                       2.0  543705   \n",
       "3                    2.0                       2.0  541073   \n",
       "4                    2.0                       2.0  572772   \n",
       "5                    2.0                       2.0  498526   \n",
       "\n",
       "   Queue Depth/Thread         ...               Stat_End_Time  \\\n",
       "1                 256         ...         2018-05-07 12:33:03   \n",
       "2                 256         ...         2018-05-07 12:35:14   \n",
       "3                 256         ...         2018-05-07 12:37:25   \n",
       "4                 256         ...         2018-05-07 12:39:37   \n",
       "5                 256         ...         2018-05-07 12:41:48   \n",
       "\n",
       "      Stat_Start_Time                                          Test_Name  \\\n",
       "1 2018-05-07 12:31:23  Sustained Multi-Threaded Sequential Read Tests...   \n",
       "2 2018-05-07 12:33:34  Sustained Multi-Threaded Sequential Read Tests...   \n",
       "3 2018-05-07 12:35:45  Sustained Multi-Threaded Sequential Read Tests...   \n",
       "4 2018-05-07 12:37:57  Sustained Multi-Threaded Sequential Read Tests...   \n",
       "5 2018-05-07 12:40:08  Sustained Multi-Threaded Sequential Read Tests...   \n",
       "\n",
       "  Threads                 Time_date           Timestamp   Timestamp_ms  Type  \\\n",
       "1       1  Mon May  7 12:33:13 2018 2018-05-07 12:33:13  1525676593609   Seq   \n",
       "2       1  Mon May  7 12:35:24 2018 2018-05-07 12:35:24  1525676724726   Seq   \n",
       "3       1  Mon May  7 12:37:35 2018 2018-05-07 12:37:35  1525676855874   Seq   \n",
       "4       1  Mon May  7 12:39:47 2018 2018-05-07 12:39:47  1525676987008   Seq   \n",
       "5       1  Mon May  7 12:41:58 2018 2018-05-07 12:41:58  1525677118124   Seq   \n",
       "\n",
       "  Write %  Write Latency (us)  \n",
       "1       0                 0.0  \n",
       "2       0                 0.0  \n",
       "3       0                 0.0  \n",
       "4       0                 0.0  \n",
       "5       0                 0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
